{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKp9QpYhmdtS"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "!pip install faiss-cpu\n",
        "!sudo apt-get install python3.10\n",
        "!sudo update-alternatives --install \"/usr/bin/python3\" python3 \"/usr/bin/python3.10\" 1\n",
        "!sudo update-alternatives --install \"/usr/bin/python3\" python3 \"/usr/bin/python3.11\" 0\n",
        "!sudo apt-get install python3-pip\n",
        "\n",
        "packages = ['build-essential', 'python3-dev', 'ffmpeg', 'aria2']\n",
        "pip_packages = ['setuptools', 'wheel', 'fairseq', 'ffmpeg', 'ffmpeg-python', 'praat-parselmouth', 'pyworld', 'numpy==1.23.5', 'numba==0.56.4', 'librosa==0.9.2', 'matplotlib==3.7.0', 'tensorboard']\n",
        "\n",
        "print(\"Updating and installing system packages...\")\n",
        "for package in packages:\n",
        "  print(f\"Installing {package}...\")\n",
        "  subprocess.check_call(['apt-get', 'install', '-qq', '-y', package])\n",
        "\n",
        "print(\"Updating and installing pip packages...\")\n",
        "\n",
        "for package in pip_packages:\n",
        "  print(f\"Installing {package}...\")\n",
        "  subprocess.check_call(['pip', 'install', '--upgrade', package])\n",
        "\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --upgrade --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "print('Packages up to date.')\n",
        "firsttry = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork\")):\n",
        "  print(\"RVC already installed, skipping.\")\n",
        "else:\n",
        "  !git clone https://github.com/Mangio621/Mangio-RVC-Fork.git\n",
        "  !git clone https://github.com/maxrmorrison/torchcrepe.git\n",
        "  !mv torchcrepe/torchcrepe Mangio-RVC-Fork/\n",
        "  !rm -rf torchcrepe  # Delete the torchcrepe repository folder\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "os.makedirs(os.path.join(now_dir, \"logs\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(now_dir, \"weights\"), exist_ok=True)"
      ],
      "metadata": {
        "id": "MEAPTWk9mkf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "ngpu = torch.cuda.device_count()\n",
        "gpu_infos = []\n",
        "mem = []\n",
        "if_gpu_ok = False\n",
        "\n",
        "if torch.cuda.is_available() or ngpu != 0:\n",
        "  for i in range(ngpu):\n",
        "    gpu_name = torch.cuda.get_device_name(i)\n",
        "    if any(\n",
        "        value in gpu_name.upper()\n",
        "        for value in [\"10\", \"16\", \"20\", \"30\", \"40\", \"A2\", \"A3\", \"A4\", \"P4\", \"A50\", \"500\", \"A60\", \"70\", \"80\", \"90\", \"M4\", \"T4\", \"TITAN\"]\n",
        "    ):\n",
        "      if_gpu_ok = True\n",
        "      print(\"Compatible GPU detected: %s\" % gpu_name)\n",
        "      gpu_infos.append(\"%s\\t%s\" % (i, gpu_name))\n",
        "      mem.append(int(torch.cuda.get_device_properties(i).total_memory / 1024 / 1024 / 1024 + 0.4))\n",
        "\n",
        "if if_gpu_ok and len(gpu_infos) > 0:\n",
        "  gpu_info = \"\\n\".join(gpu_infos)\n",
        "\n",
        "else:\n",
        "  raise Exception(\"No GPU detected; training cannot continue. Please change your runtime type to a GPU.\")\n",
        "gpus = \"-\".join(i[0] for i in gpu_infos)"
      ],
      "metadata": {
        "id": "ewAyhB7imma-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print('Drive is already mounted. Proceed.')\n",
        "\n",
        "os.makedirs('/content/drive/MyDrive/rvcDisconnected', exist_ok=True)"
      ],
      "metadata": {
        "id": "PkHITq3Vmoa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/hubert_base.pt -d /content/Mangio-RVC-Fork -o hubert_base.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/rmvpe.pt -d /content/Mangio-RVC-Fork -o rmvpe.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kit-Lemonfoot/RVC_DidntAsk/resolve/main/40k.json -d /content/Mangio-RVC-Fork/configs -o 40k.json\n"
      ],
      "metadata": {
        "id": "ZctGG74BmsXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup CSVDB\n",
        "#...Alright, you made your point.\n",
        "import csv\n",
        "\n",
        "if not os.path.isdir(\"csvdb/\"):\n",
        "  os.makedirs(\"csvdb\")\n",
        "  frmnt, stp = open(\"csvdb/formanting.csv\", \"w\", newline=\"\"), open(\"csvdb/stop.csv\", \"w\", newline=\"\")\n",
        "  csv_writer = csv.writer(frmnt, delimiter=\",\")\n",
        "  csv_writer.writerow([False, 1.0, 1.0])\n",
        "  csv_writer = csv.writer(stp, delimiter=\",\")\n",
        "  csv_writer.writerow([False])\n",
        "  frmnt.close()\n",
        "  stp.close()\n",
        "\n",
        "global DoFormant, Quefrency, Timbre\n",
        "DoFormant, Quefrency, Timbre = False, 1.0, 1.0"
      ],
      "metadata": {
        "id": "J4-5iw1Lmugi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now_dir = \"/content/Mangio-RVC-Fork\"\n",
        "experiment_name = \"viveknewer\"\n",
        "path_to_training_folder = \"/content/dataset/\"\n",
        "model_architecture = \"v2\"\n",
        "target_sample_rate = \"40k\"\n",
        "speaker_id = 0\n",
        "pitch_extraction_algorithm = \"rmvpe\"\n",
        "crepe_hop_length = 64\n",
        "pitch_guidance = True\n",
        "\n",
        "cpu_threads = !nproc\n",
        "cpu_threads = int(cpu_threads[0])\n",
        "\n",
        "exp_dir = f\"{now_dir}/logs/{experiment_name}\"\n",
        "\n",
        "assert crepe_hop_length!=None,\n",
        "assert crepe_hop_length>0,\n",
        "assert crepe_hop_length<=512,\n",
        "\n",
        "if(experiment_name == \"experiment_name\"):\n",
        "  print(\"Warning: Your experiment name should be changed to the name of your dataset.\")"
      ],
      "metadata": {
        "id": "-C8onDwtmxAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set required values\n",
        "target_sample_rate = \"40k\"  # Change to \"32k\" or \"48k\" if needed and available\n",
        "model_architecture = \"v2\"\n",
        "\n",
        "# Set TITAN model URLs\n",
        "g = f\"https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/{target_sample_rate}/pretrained/G-f0{target_sample_rate}-TITAN-Medium.pth\"\n",
        "d = f\"https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/{target_sample_rate}/pretrained/D-f0{target_sample_rate}-TITAN-Medium.pth\"\n",
        "\n",
        "# Set download path based on architecture\n",
        "pretrained_base = \"pretrained_v2/\"\n",
        "\n",
        "# Create path if it doesn't exist (only necessary outside Colab)\n",
        "import os\n",
        "os.makedirs(f\"/content/Mangio-RVC-Fork/{pretrained_base}\", exist_ok=True)\n",
        "\n",
        "# Download using aria2c\n",
        "print(\"Downloading TITAN pretrained model...\")\n",
        "!aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {g} -d /content/Mangio-RVC-Fork/{pretrained_base} -o f0G{target_sample_rate}_TITAN.pth\n",
        "!aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {d} -d /content/Mangio-RVC-Fork/{pretrained_base} -o f0D{target_sample_rate}_TITAN.pth\n",
        "print(\"TITAN pretrained model downloaded successfully.\")\n"
      ],
      "metadata": {
        "id": "hiuE2YVpmxgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"vivek2.0.zip\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "directories=[]\n",
        "\n",
        "def sanitize_directory(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "      if filename == \".DS_Store\" or filename.startswith(\"._\") or not filename.endswith(('.wav', '.flac', '.mp3', '.ogg', '.m4a')):\n",
        "        os.remove(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "      if(filename == \"__MACOSX\"):\n",
        "        shutil.rmtree(file_path)\n",
        "        continue\n",
        "      directories.append(file_path)\n",
        "      sanitize_directory(file_path)\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/rvcDisconnected/' + dataset\n",
        "final_directory = '/content/dataset'\n",
        "temp_directory = '/content/temp_dataset'\n",
        "\n",
        "if os.path.exists(final_directory):\n",
        "  print(\"Dataset folder already found. Wiping...\")\n",
        "  shutil.rmtree(final_directory)\n",
        "if os.path.exists(temp_directory):\n",
        "  print(\"Temporary folder already found. Wiping...\")\n",
        "  shutil.rmtree(temp_directory)\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "  raise Exception(f'I can\\'t find {dataset} in {os.path.dirname(dataset_path)}.')\n",
        "\n",
        "os.makedirs(final_directory, exist_ok=True)\n",
        "os.makedirs(temp_directory, exist_ok=True)\n",
        "#Oops.\n",
        "!unzip -d \"{temp_directory}\" -B \"{dataset_path}\"\n",
        "print(\"Sanitizing...\")\n",
        "sanitize_directory(temp_directory)\n",
        "\n",
        "if(len(directories) == 0):\n",
        "  print(\"Dataset Type: Audio Files (Single Speaker)\")\n",
        "  expDir=os.path.join(final_directory, experiment_name)\n",
        "  os.makedirs(expDir, exist_ok=True)\n",
        "  for r, _, f in os.walk(temp_directory):\n",
        "    for name in f:\n",
        "      !cp \"{temp_directory}/{name}\" \"{expDir}\"\n",
        "elif(len(directories) == 1):\n",
        "  print(\"Dataset Type: Single Speaker\")\n",
        "  fi = os.path.join(temp_directory, experiment_name)\n",
        "  os.rename(directories[0], fi)\n",
        "  shutil.move(fi, final_directory)\n",
        "\n",
        "else:\n",
        "  print(\"Dataset Type: Multispeaker\")\n",
        "  for fi in directories:\n",
        "    shutil.move(fi, final_directory)\n",
        "\n",
        "shutil.rmtree(temp_directory)\n",
        "\n",
        "print(\"Dataset imported.\")\n"
      ],
      "metadata": {
        "id": "FDN4AijCm0Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loc = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "!zip -r rvcLogs.zip \"{loc}\"\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "!mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "!cp /content/Mangio-RVC-Fork/rvcLogs.zip \"{DATASET_PATH_DRIVE}\""
      ],
      "metadata": {
        "id": "Ft4Svr09m3OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BACK_UP_DATASET_PATH = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "\n",
        "#Prevent people from loading the ZIP over existing files\n",
        "ok=True\n",
        "if(os.path.exists(\"/content/Mangio-RVC-Fork/logs/\"+experiment_name+\"/2a_f0\")):\n",
        "  print(\"Dataset files already loaded, skipping.\")\n",
        "  ok=False\n",
        "\n",
        "if ok:\n",
        "  !unzip \"{BACK_UP_DATASET_PATH}/rvcLogs.zip\" -d /"
      ],
      "metadata": {
        "id": "BFI5Y1xUm5Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "exp_dir = \"%s/logs/%s\" % (now_dir, experiment_name)\n",
        "os.makedirs(exp_dir, exist_ok=True)\n",
        "feature_dir = (\n",
        "    \"%s/3_feature256\" % (exp_dir)\n",
        "    if model_architecture == \"v1\"\n",
        "    else \"%s/3_feature768\" % (exp_dir)\n",
        ")\n",
        "print(feature_dir)\n",
        "if not os.path.exists(feature_dir):\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "listdir_res = list(os.listdir(feature_dir))\n",
        "if len(listdir_res) == 0:\n",
        "  raise Exception(\"No features exist for this model yet. Did you run Feature Extraction?\")\n",
        "\n",
        "try:\n",
        "  from sklearn.cluster import MiniBatchKMeans\n",
        "except:\n",
        "  print(\"Due to a bug with Colab, we will need to reinstall Numpy real quick. Give me a sec!\")\n",
        "  !pip install -U numpy\n",
        "  print(\"Numpy reinstalled. Please restart the runtime, and then re-run the \\\"Set Training Variables\\\" cell to continue.\")\n",
        "  sys.exit()\n",
        "else:\n",
        "  print(\"Proper Numpy version detected.\")\n",
        "\n",
        "infos=[]\n",
        "npys=[]\n",
        "for name in sorted(listdir_res):\n",
        "  phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "  npys.append(phone)\n",
        "big_npy = np.concatenate(npys, 0)\n",
        "big_npy_idx = np.arange(big_npy.shape[0])\n",
        "np.random.shuffle(big_npy_idx)\n",
        "if big_npy.shape[0] > 2e5 or force_mbkm:\n",
        "  print(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "  try:\n",
        "    big_npy = (\n",
        "        MiniBatchKMeans(\n",
        "            n_clusters=10000,\n",
        "            verbose=True,\n",
        "            batch_size=256,\n",
        "            compute_labels = False,\n",
        "            init=\"random\"\n",
        "        )\n",
        "        .fit(big_npy)\n",
        "        .cluster_centers_\n",
        "\n",
        "    )\n",
        "  except:\n",
        "    info = traceback.format_exc()\n",
        "    print(info)\n",
        "\n",
        "np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "n_ivf = min(int(16*np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "print(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "index = faiss.index_factory(256 if model_architecture == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "print(\"Training index...\")\n",
        "index_ivf = faiss.extract_index_ivf(index)\n",
        "index_ivf.nprobe = 1\n",
        "index.train(big_npy)\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\" % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "print(\"Adding...\")\n",
        "batch_size_add = 8192\n",
        "for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "  index.add(big_npy[i:i+batch_size_add])\n",
        "faiss.write_index(\n",
        "    index,\n",
        "    \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "    % (exp_dir, n_ivf, index_ivf.nprobe, experiment_name, model_architecture)\n",
        ")\n",
        "\n",
        "npr = index_ivf.nprobe\n",
        "\n",
        "print(\"Saving files to Drive...\")\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(save_extra_files_to_drive):\n",
        "  !cp \"{DATASET_PATH_COLAB}/total_fea.npy\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/trained_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "!cp \"{DATASET_PATH_COLAB}/added_IVF{n_ivf}_Flat_nprobe_{npr}_{experiment_name}_{model_architecture}.index\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done! Your index file has completed training.\")\n",
        "try:\n",
        "  firsttry\n",
        "except:\n",
        "  print(\"If you had to restart the runtime, disconnect and delete the runtime in order to continue. (Restarting the runtime again will not work.)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GzO5wuEQm66Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "STEPCOUNT = 2333333\n",
        "\n",
        "print(\"Copying model files...\")\n",
        "!cp \"{DATASET_PATH_DRIVE}/D_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/G_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\")):\n",
        "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"All done. Welcome back!\")"
      ],
      "metadata": {
        "id": "Bun-EXjFm_Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING\n",
        "import os\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "assert 'model_architecture' in locals(),\n",
        "\n",
        "assert 'pretrain_type' in locals(),\n",
        "\n",
        "save_frequency = 10\n",
        "total_epochs = 1850\n",
        "batch_size = 8\n",
        "save_only_latest_ckpt = True\n",
        "cache_all_training_sets = False\n",
        "save_small_final_model = True\n",
        "\n",
        "\n",
        "assert save_frequency!=None,\n",
        "assert save_frequency>0,\n",
        "if(save_frequency>50):print(f\"...A save frequency of {save_frequency}? A bit high, but... alright then.\")\n",
        "assert total_epochs!=None, \"\n",
        "assert total_epochs>0,\n",
        "if(total_epochs>10000):print(f\"...A total epoch count of of {total_epochs}? This is going to overtrain, but... alright then.\")\n",
        "assert batch_size!=None,\n",
        "assert batch_size>0,\n",
        "assert batch_size<=40,\n",
        "\n",
        "pretrained_base = \"pretrained/\" if model_architecture == \"v1\" else \"pretrained_v2/\"\n",
        "unpt = f\"_{pretrain_type}\" if pretrain_type!=\"original\" else \"\"\n",
        "\n",
        "pretrainedD = f\"{pretrained_base}f0D{target_sample_rate}{unpt}.pth\"\n",
        "pretrainedG = f\"{pretrained_base}f0G{target_sample_rate}{unpt}.pth\"\n",
        "\n",
        "log_interval = 1\n",
        "liFolderPath = os.path.join(exp_dir, \"1_16k_wavs\")\n",
        "if(os.path.exists(liFolderPath) and os.path.isdir(liFolderPath)):\n",
        "  wav_files = [f for f in os.listdir(liFolderPath) if f.endswith(\".wav\")]\n",
        "  if wav_files:\n",
        "    sample_size = len(wav_files)\n",
        "    log_interval = math.ceil(sample_size / batch_size)\n",
        "    if log_interval > 1:\n",
        "      log_interval += 1\n",
        "\n",
        "if log_interval > 250 and not use_manual_stepToEpoch:\n",
        "  print(f\"That's a big dataset you got there. Log interval normalized to 200 steps from {log_interval} steps.\")\n",
        "  log_interval = 200\n",
        "\n",
        "if use_manual_stepToEpoch:\n",
        "  log_interval = manual_stepToEpoch\n",
        "\n",
        "cmd = \"python train_nsf_sim_cache_sid_load_pretrain.py -e \\\"%s\\\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s -li %s\" % (\n",
        "    experiment_name,\n",
        "    target_sample_rate,\n",
        "    1,\n",
        "    batch_size,\n",
        "    0,\n",
        "    total_epochs,\n",
        "    save_frequency,\n",
        "    \"-pg %s\" % pretrainedG if pretrainedG != \"\" else \"\\b\",\n",
        "    \"-pd %s\" % pretrainedD if pretrainedD != \"\" else \"\\b\",\n",
        "    1 if save_only_latest_ckpt else 0,\n",
        "    1 if cache_all_training_sets else 0,\n",
        "    1 if save_small_final_model else 0,\n",
        "    model_architecture,\n",
        "    log_interval,\n",
        ")\n",
        "print(cmd)\n",
        "\n",
        "gt_wavs_dir = f\"{exp_dir}/0_gt_wavs\"\n",
        "feature_dir = (\n",
        "  f\"{exp_dir}/3_feature256\"\n",
        "  if model_architecture == \"v1\"\n",
        "  else f\"{exp_dir}/3_feature768\"\n",
        ")\n",
        "f0_dir = f\"{exp_dir}/2a_f0\"\n",
        "f0nsf_dir = f\"{exp_dir}/2b-f0nsf\"\n",
        "names = (\n",
        "  set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "  & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        ")\n",
        "opt = []\n",
        "for name in names:\n",
        "  opt.append(\n",
        "    \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "    % (\n",
        "      gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "      name,\n",
        "      speaker_id,\n",
        "    )\n",
        "  )\n",
        "fea_dim = 256 if model_architecture == \"v1\" else 768\n",
        "for _ in range(2):\n",
        "  opt.append(\n",
        "      f\"{now_dir}/logs/mute/0_gt_wavs/mute{target_sample_rate}.wav|{now_dir}/logs/mute/3_feature{fea_dim}/mute.npy|{now_dir}/logs/mute/2a_f0/mute.wav.npy|{now_dir}/logs/mute/2b-f0nsf/mute.wav.npy|{speaker_id}\"\n",
        "  )\n",
        "shuffle(opt)\n",
        "with open(f\"{exp_dir}/filelist.txt\", \"w\") as f:\n",
        "  f.write(\"\\n\".join(opt))\n",
        "print(\"Mute filelist written. Best of luck training!\")\n",
        "\n",
        "os.chdir('/content/Mangio-RVC-Fork')\n",
        "\n",
        "log_file = f\"{exp_dir}/training_log.txt\"\n",
        "print(f\"Training logs will be saved to: {log_file}\")\n",
        "\n",
        "import subprocess\n",
        "print(\"Starting training process...\")\n",
        "with open(log_file, \"w\") as f:\n",
        "    process = subprocess.Popen(\n",
        "        cmd,\n",
        "        shell=True,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')\n",
        "        f.write(line)\n",
        "        f.flush()\n",
        "\n",
        "    process.wait()\n",
        "\n",
        "print(f\"Training completed. Check log file at {log_file}\")"
      ],
      "metadata": {
        "id": "_vc6MOcDnBEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "STEPCOUNT = 2333333\n",
        "\n",
        "print(\"Copying model files...\")\n",
        "!cp \"{DATASET_PATH_DRIVE}/D_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/G_{STEPCOUNT}.pth\" \"{DATASET_PATH_COLAB}\"\n",
        "!cp \"{DATASET_PATH_DRIVE}/config.json\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, _, f in os.walk(DATASET_PATH_DRIVE):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\")):\n",
        "      !cp \"{DATASET_PATH_DRIVE}/{name}\" \"{DATASET_PATH_COLAB}\"\n",
        "\n",
        "print(\"All done. Welcome back!\")"
      ],
      "metadata": {
        "id": "HAjt53SSnBfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATASET_PATH_DRIVE = \"/content/drive/MyDrive/rvcDisconnected/\" + experiment_name\n",
        "DATASET_PATH_COLAB = \"/content/Mangio-RVC-Fork/logs/\" + experiment_name\n",
        "if(not os.path.exists(DATASET_PATH_DRIVE)):\n",
        "  !mkdir -p \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "STEPCOUNT = 2333333\n",
        "EPOCHCOUNT = 2333333\n",
        "\n",
        "finished=False\n",
        "potential=\"/content/Mangio-RVC-Fork/weights/\"+experiment_name+\".pth\"\n",
        "if os.path.exists(potential):\n",
        "  finished = True\n",
        "\n",
        "print(\"Detecting latest model...\")\n",
        "if(not manual_save):\n",
        "  currentMax = 0\n",
        "  for r, _, f in os.walk(\"/content/Mangio-RVC-Fork/weights/\"):\n",
        "    for name in f:\n",
        "      if(name.endswith(\".pth\") and (name!=experiment_name+\".pth\")):\n",
        "        if(name.find(experiment_name)==-1):\n",
        "          continue\n",
        "        pot = name.split('_')\n",
        "        ep=pot[len(pot)-2][1:]\n",
        "        if(not ep.isdecimal()):\n",
        "          continue\n",
        "        ep=int(ep)\n",
        "        if ep>currentMax:\n",
        "          currentMax=ep\n",
        "          step=pot[len(pot)-1].split('.')\n",
        "          step=int(step[0][1:])\n",
        "          EPOCHCOUNT=ep\n",
        "          STEPCOUNT=step\n",
        "\n",
        "TSTEP = STEPCOUNT\n",
        "if(not skip_models):\n",
        "  print(\"Copying model files...\")\n",
        "  if(save_only_latest_ckpt):\n",
        "    TSTEP=2333333\n",
        "  !cp \"{DATASET_PATH_COLAB}/D_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/G_{TSTEP}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "  !cp \"{DATASET_PATH_COLAB}/config.json\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying Tensorboard TFEVENT files...\")\n",
        "for r, d, f in os.walk(DATASET_PATH_COLAB):\n",
        "  for name in f:\n",
        "    if(name.startswith(\"events.out.tfevents\") and os.path.exists(os.path.join(DATASET_PATH_COLAB, name))):\n",
        "      !cp \"{DATASET_PATH_COLAB}/{name}\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"Copying weight file...\")\n",
        "if(finished):\n",
        "  !cp \"{potential}\" \"{DATASET_PATH_DRIVE}\"\n",
        "else:\n",
        "  !cp \"/content/Mangio-RVC-Fork/weights/{experiment_name}_e{EPOCHCOUNT}_s{STEPCOUNT}.pth\" \"{DATASET_PATH_DRIVE}\"\n",
        "\n",
        "print(\"All done!\")"
      ],
      "metadata": {
        "id": "vepP95AJnGMC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}